{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southeast-commonwealth",
   "metadata": {},
   "source": [
    "# Chapter 3 Clustering – Finding Related Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "spread-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-expression",
   "metadata": {},
   "source": [
    "## Preprocessing – similarity measured as a similar number of common words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-universe",
   "metadata": {},
   "source": [
    "### Converting raw text into a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gorgeous-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regular-insulin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to format my hard disk', ' Hard disk format problems ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = [\"How to format my hard disk\", \" Hard disk format problems \"]\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "crucial-guinea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disk', 'format', 'hard', 'how', 'my', 'problems', 'to']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = vectorizer.fit_transform(content)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exceptional-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "experimental-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.txt', '02.txt', '03.txt', '04.txt', '05.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = \"./data/toy\"\n",
    "sorted(os.listdir(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adverse-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a toy post about machine learning. Actually, it contains not much interesting stuff.\\n',\n",
       " 'Imaging databases provide storage capabilities.\\n',\n",
       " 'Most imaging databases save images permanently.\\n',\n",
       " 'Imaging databases store data.\\n',\n",
       " 'Imaging databases store data. Imaging databases store data. Imaging databases store data.\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = [open(os.path.join(DIR, f)).read() for f in sorted(os.listdir(DIR))]\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "affecting-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 25\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "print(f\"#samples: {num_samples}, #features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "numerous-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'actually', 'capabilities', 'contains', 'data', 'databases', 'images', 'imaging', 'interesting', 'is', 'it', 'learning', 'machine', 'most', 'much', 'not', 'permanently', 'post', 'provide', 'save', 'storage', 'store', 'stuff', 'this', 'toy']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "owned-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print(new_post_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "grateful-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "natural-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_raw(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return np.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "painted-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist = 4.00 : This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "\n",
      "=== Post 1 with dist = 1.73 : Imaging databases provide storage capabilities.\n",
      "\n",
      "=== Post 2 with dist = 2.00 : Most imaging databases save images permanently.\n",
      "\n",
      "=== Post 3 with dist = 1.41 : Imaging databases store data.\n",
      "\n",
      "=== Post 4 with dist = 5.10 : Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "\n",
      "Best post is 3 with dist = 1.41\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "best_doc = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "\n",
    "for i, post in enumerate(posts):\n",
    "    if post == new_post:\n",
    "        continue\n",
    "        \n",
    "    post_vec = X_train.getrow(i)\n",
    "    \n",
    "    d = dist_raw(post_vec, new_post_vec)\n",
    "    \n",
    "    print(f\"=== Post {i} with dist = {d:.2f} : {post}\")\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i \n",
    "        \n",
    "print(f\"Best post is {best_i} with dist = {best_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "graphic-discount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]]\n",
      "[[0 0 0 0 3 3 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.getrow(3).toarray())\n",
    "print(X_train.getrow(4).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "supposed-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_norm(v1, v2):\n",
    "    v1_normalized = v1/np.linalg.norm(v1.toarray())\n",
    "    v2_normalized = v2/np.linalg.norm(v2.toarray())\n",
    "    delta = v1_normalized - v2_normalized \n",
    "    return np.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cognitive-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist = 1.41 : This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "\n",
      "=== Post 1 with dist = 0.86 : Imaging databases provide storage capabilities.\n",
      "\n",
      "=== Post 2 with dist = 0.92 : Most imaging databases save images permanently.\n",
      "\n",
      "=== Post 3 with dist = 0.77 : Imaging databases store data.\n",
      "\n",
      "=== Post 4 with dist = 0.77 : Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "\n",
      "Best post is 3 with dist = 0.77\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "\n",
    "for i, post in enumerate(posts):\n",
    "    if post == new_post:\n",
    "        continue\n",
    "        \n",
    "    post_vec = X_train.getrow(i)\n",
    "    \n",
    "    d = dist_norm(post_vec, new_post_vec)\n",
    "    \n",
    "    print(f\"=== Post {i} with dist = {d:.2f} : {post}\")\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i \n",
    "        \n",
    "print(f\"Best post is {best_i} with dist = {best_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dominican-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "print(sorted(vectorizer.get_stop_words())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "valid-pencil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 18\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "print(f\"#samples: {num_samples}, #features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "athletic-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print(new_post_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "hired-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist = 1.41 : This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "\n",
      "=== Post 1 with dist = 0.86 : Imaging databases provide storage capabilities.\n",
      "\n",
      "=== Post 2 with dist = 0.86 : Most imaging databases save images permanently.\n",
      "\n",
      "=== Post 3 with dist = 0.77 : Imaging databases store data.\n",
      "\n",
      "=== Post 4 with dist = 0.77 : Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "\n",
      "Best post is 3 with dist = 0.77\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "\n",
    "for i, post in enumerate(posts):\n",
    "    if post == new_post:\n",
    "        continue\n",
    "        \n",
    "    post_vec = X_train.getrow(i)\n",
    "    \n",
    "    d = dist_norm(post_vec, new_post_vec)\n",
    "    \n",
    "    print(f\"=== Post {i} with dist = {d:.2f} : {post}\")\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i \n",
    "        \n",
    "print(f\"Best post is {best_i} with dist = {best_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "biological-audience",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "protective-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphic'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nltk.stem.SnowballStemmer('english')\n",
    "s.stem(\"graphics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fresh-investor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"imaging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "vulnerable-denver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "electrical-launch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imagin'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"imagination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "meaningful-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imagin'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"imagine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "expensive-chemical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"buys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "hired-brunswick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"buying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "alone-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bought'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "expressed-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "compliant-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "nonprofit-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = StemmedCountVectorizer(min_df=1, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "twenty-investment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 17\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "print(f\"#samples: {num_samples}, #features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "differential-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print(new_post_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bridal-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist = 1.41 : This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "\n",
      "=== Post 1 with dist = 0.86 : Imaging databases provide storage capabilities.\n",
      "\n",
      "=== Post 2 with dist = 0.63 : Most imaging databases save images permanently.\n",
      "\n",
      "=== Post 3 with dist = 0.77 : Imaging databases store data.\n",
      "\n",
      "=== Post 4 with dist = 0.77 : Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "\n",
      "Best post is 2 with dist = 0.63\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "\n",
    "for i, post in enumerate(posts):\n",
    "    if post == new_post:\n",
    "        continue\n",
    "        \n",
    "    post_vec = X_train.getrow(i)\n",
    "    \n",
    "    d = dist_norm(post_vec, new_post_vec)\n",
    "    \n",
    "    print(f\"=== Post {i} with dist = {d:.2f} : {post}\")\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i \n",
    "        \n",
    "print(f\"Best post is {best_i} with dist = {best_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hearing-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(term, doc, corpus):\n",
    "    tf = doc.count(term)/len(doc)\n",
    "    num_docs_with_term = len([d for d in corpus if term in d])\n",
    "    idf = np.log(len(corpus)/ num_docs_with_term)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "living-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, abb, abc = [\"a\"], [\"a\", \"b\", \"b\"], [\"a\", \"b\", \"c\"]\n",
    "D = [a, abb, abc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "straight-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"a\", a, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "limiting-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"a\", abb, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cooked-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"a\", abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "pending-domestic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27031007207210955"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"b\", abb, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "recent-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13515503603605478"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"b\", abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "inside-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3662040962227032"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"c\", abc, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intellectual-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mobile-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc : (\n",
    "            english_stemmer.stem(w) for w in analyzer(doc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "exposed-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=1, \n",
    "                                    stop_words='english',\n",
    "                                    decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "broken-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 5, #features: 17\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "num_samples, num_features = X_train.shape\n",
    "print(f\"#samples: {num_samples}, #features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "present-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.7071067811865476\n",
      "  (0, 4)\t0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print(new_post_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "valued-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Post 0 with dist = 1.41 : This is a toy post about machine learning. Actually, it contains not much interesting stuff.\n",
      "\n",
      "=== Post 1 with dist = 1.08 : Imaging databases provide storage capabilities.\n",
      "\n",
      "=== Post 2 with dist = 0.86 : Most imaging databases save images permanently.\n",
      "\n",
      "=== Post 3 with dist = 0.92 : Imaging databases store data.\n",
      "\n",
      "=== Post 4 with dist = 0.92 : Imaging databases store data. Imaging databases store data. Imaging databases store data.\n",
      "\n",
      "Best post is 2 with dist = 0.86\n"
     ]
    }
   ],
   "source": [
    "best_doc = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "\n",
    "for i, post in enumerate(posts):\n",
    "    if post == new_post:\n",
    "        continue\n",
    "        \n",
    "    post_vec = X_train.getrow(i)\n",
    "    \n",
    "    d = dist_norm(post_vec, new_post_vec)\n",
    "    \n",
    "    print(f\"=== Post {i} with dist = {d:.2f} : {post}\")\n",
    "    if d < best_dist:\n",
    "        best_dist = d\n",
    "        best_i = i \n",
    "        \n",
    "print(f\"Best post is {best_i} with dist = {best_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-tattoo",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-madness",
   "metadata": {},
   "source": [
    "### Getting test data to evaluate our ideas on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informative-compensation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "all_data = sklearn.datasets.fetch_20newsgroups(subset='all')\n",
    "len(all_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subsequent-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(all_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "explicit-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = sklearn.datasets.fetch_20newsgroups(subset='train')\n",
    "len(train_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "magnetic-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = sklearn.datasets.fetch_20newsgroups(subset='test')\n",
    "len(test_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
    "    'comp.sys.mac.hardware', 'comp.windows.x', 'sci.space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "small-telephone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = sklearn.datasets.fetch_20newsgroups(subset='train', categories=groups)\n",
    "len(train_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "national-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = sklearn.datasets.fetch_20newsgroups(subset='test', categories=groups)\n",
    "len(test_data.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-traffic",
   "metadata": {},
   "source": [
    "### Clustering Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlimited-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=10, \n",
    "                                    max_df=0.5,\n",
    "                                    stop_words='english', \n",
    "                                    decode_error='ignore')\n",
    "vectorized = vectorizer.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "embedded-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 3529, #features: 4712\n"
     ]
    }
   ],
   "source": [
    "num_samples, num_features = vectorized.shape\n",
    "print(f\"#samples: {num_samples}, #features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "opposite-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "detailed-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 5925.977358309683\n",
      "Iteration 1, inertia 3215.2590433087403\n",
      "Iteration 2, inertia 3179.199640805428\n",
      "Iteration 3, inertia 3157.765345523002\n",
      "Iteration 4, inertia 3144.332597910992\n",
      "Iteration 5, inertia 3135.2342147507306\n",
      "Iteration 6, inertia 3128.664551177874\n",
      "Iteration 7, inertia 3124.756954533032\n",
      "Iteration 8, inertia 3121.5927166252527\n",
      "Iteration 9, inertia 3118.7882911899205\n",
      "Iteration 10, inertia 3116.091638786711\n",
      "Iteration 11, inertia 3114.0968233171616\n",
      "Iteration 12, inertia 3113.016740705259\n",
      "Iteration 13, inertia 3112.1027671605866\n",
      "Iteration 14, inertia 3111.131954036844\n",
      "Iteration 15, inertia 3110.593491559183\n",
      "Iteration 16, inertia 3110.3333672920667\n",
      "Iteration 17, inertia 3110.2593476388543\n",
      "Iteration 18, inertia 3110.232825401951\n",
      "Iteration 19, inertia 3110.184785024758\n",
      "Converged at iteration 19: strict convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=50, n_init=1, random_state=3, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 50\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, \n",
    "            init='random', \n",
    "            n_init=1,\n",
    "           verbose=1,\n",
    "           random_state=3)\n",
    "\n",
    "km.fit(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "plastic-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 12 25 ... 42  9  8]\n"
     ]
    }
   ],
   "source": [
    "print(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "junior-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3529,)\n"
     ]
    }
   ],
   "source": [
    "print(km.labels_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-baghdad",
   "metadata": {},
   "source": [
    "## Solving our initial challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "gothic-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Disk drive problems. Hi, I have a problem with my hard disk. After 1 year it is working only sporadically now.I tried to format it, but now it doesn't boot any more.Any ideas? Thanks.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post = \"Disk drive problems. Hi, I have a problem with my hard \\\n",
    "disk. After 1 year it is working only sporadically now.\\\n",
    "I tried to format it, but now it doesn't boot any more.\\\n",
    "Any ideas? Thanks.\"\n",
    "new_post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unable-attachment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_post_vec = vectorizer.transform([new_post])\n",
    "new_post_label = km.predict(new_post_vec)[0]\n",
    "new_post_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "modern-crossing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_indices = (km.labels_==new_post_label).nonzero()[0]\n",
    "len(similar_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "economic-anniversary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = []\n",
    "\n",
    "for i in similar_indices:\n",
    "    dist = np.linalg.norm((new_post_vec - vectorized[i]).toarray())\n",
    "    similar.append((dist, train_data.data[i]))\n",
    "                   \n",
    "similar = sorted(similar)\n",
    "len(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dirty-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_at_1 = similar[0]\n",
    "show_at_2 = similar[int(len(similar)/10)]\n",
    "show_at_3 = similar[int(len(similar)/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "devoted-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0378441731334072 \t From: Thomas Dachsel <GERTHD@mvs.sas.com>\n",
      "Subject: BOOT PROBLEM with IDE controller\n",
      "Nntp-Posting-Host: sdcmvs.mvs.sas.com\n",
      "Organization: SAS Institute Inc.\n",
      "Lines: 25\n",
      "\n",
      "Hi,\n",
      "I've got a Multi I/O card (IDE controller + serial/parallel\n",
      "interface) and two floppy drives (5 1/4, 3 1/2) and a\n",
      "Quantum ProDrive 80AT connected to it.\n",
      "I was able to format the hard disk, but I could not boot from\n",
      "it. I can boot from drive A: (which disk drive does not matter)\n",
      "but if I remove the disk from drive A and press the reset switch,\n",
      "the LED of drive A: continues to glow, and the hard disk is\n",
      "not accessed at all.\n",
      "I guess this must be a problem of either the Multi I/o card\n",
      "or floppy disk drive settings (jumper configuration?)\n",
      "Does someone have any hint what could be the reason for it.\n",
      "Please reply by email to GERTHD@MVS.SAS.COM\n",
      "Thanks,\n",
      "Thomas\n",
      "+-------------------------------------------------------------------+\n",
      "| Thomas Dachsel                                                    |\n",
      "| Internet: GERTHD@MVS.SAS.COM                                      |\n",
      "| Fidonet:  Thomas_Dachsel@camel.fido.de (2:247/40)                 |\n",
      "| Subnet:   dachsel@rnivh.rni.sub.org (UUCP in Germany, now active) |\n",
      "| Phone:    +49 6221 4150 (work), +49 6203 12274 (home)             |\n",
      "| Fax:      +49 6221 415101                                         |\n",
      "| Snail:    SAS Institute GmbH, P.O.Box 105307, D-W-6900 Heidelberg |\n",
      "| Tagline:  One bad sector can ruin a whole day...                  |\n",
      "+-------------------------------------------------------------------+\n",
      "\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [show_at_1, show_at_2, show_at_2]:\n",
    "    print(f\"{i[0]} \\t {i[1]}\")\n",
    "    print(\"-------------------\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-yesterday",
   "metadata": {},
   "source": [
    "#### Another Look at Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "meaning-roberts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245,\n",
       " 'From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: test....(sorry)\\nOrganization: The University of Birmingham, United Kingdom\\nLines: 1\\nNNTP-Posting-Host: ibm3090.bham.ac.uk\\n\\n==============================================================================\\n',\n",
       " 'comp.graphics')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_group = zip(train_data.data, train_data.target)\n",
    "all = [(len(post[0]), post[0], train_data.target_names[post[1]]) \n",
    "       for post in post_group]\n",
    "\n",
    "graphics = sorted([post for post in all if post[2]=='comp.graphics'])\n",
    "graphics[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "naval-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['situnaya', 'ibm3090', 'bham', 'ac', 'uk', 'subject', 'test', 'sorri', 'organ', 'univers', 'birmingham', 'unit', 'kingdom', 'line', 'nntp', 'post', 'host', 'ibm3090', 'bham', 'ac', 'uk']\n"
     ]
    }
   ],
   "source": [
    "noise_post = graphics[5][1]\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "print(list(analyzer(noise_post)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "solar-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ac', 'birmingham', 'host', 'kingdom', 'nntp', 'sorri', 'test', 'uk', 'unit', 'univers']\n"
     ]
    }
   ],
   "source": [
    "useful = set(analyzer(noise_post)).intersection(vectorizer.get_feature_names())\n",
    "print(sorted(useful))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "isolated-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF(ac) = 3.51    \n",
      "IDF(birmingham) = 6.77    \n",
      "IDF(host) = 1.74    \n",
      "IDF(kingdom) = 6.68    \n",
      "IDF(nntp) = 1.77    \n",
      "IDF(sorri) = 4.14    \n",
      "IDF(test) = 3.83    \n",
      "IDF(uk) = 3.70    \n",
      "IDF(unit) = 4.42    \n",
      "IDF(univers) = 1.91    \n"
     ]
    }
   ],
   "source": [
    "for term in sorted(useful):\n",
    "    print(f\"IDF({term}) =\\\n",
    " {vectorizer._tfidf.idf_[vectorizer.vocabulary_[term]]:.2f}\\\n",
    "    \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
